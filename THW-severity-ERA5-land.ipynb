{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting terrestrial heatwaves in Australia  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to take in daily tmax data, along with previously computed mean climatology and threshold values, process these and output all the THW events that occur in the dataset\n",
    "\n",
    "First, we import the data and required modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "import dask.array\n",
    "import datetime\n",
    "from datetime import date \n",
    "from datetime import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage.measurements import label, find_objects\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-20.10/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46137 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39767</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:46137/status' target='_blank'>http://127.0.0.1:46137/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>15.60 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39767' processes=4 threads=4, memory=15.60 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dask.distributed\n",
    "threads_per_worker = 1\n",
    "try:\n",
    "    c # Already running\n",
    "except NameError:\n",
    "    c = dask.distributed.Client(\n",
    "        n_workers=4,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        memory_limit=f'{3.9*threads_per_worker}gb'\n",
    "    )\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will make the climatology and threshold repeatable so that the shapes of climatology, threshold and observation are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_clim(target_da,input_da):\n",
    "    t_time=target_da[\"time\"].dt.dayofyear[0]\n",
    "    target_da[:] = input_da.sel(dayofyear=t_time)\n",
    "    return(target_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'calc_severity()' calculates severity based on the severity index introduced by Hobday et al (2018) for categorizing marine heatwaves.\n",
    "\n",
    "This function merges together the chunks along the time dimension by setting the 'time' chunk size to None, so that the resulting chunks each contain the full time series for that location. To run the severity calculaion on each timeseries chunk, '.map_blocks()' is used so that the calculation can be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_severity(data, new_climatology, new_threshold):\n",
    "\n",
    "    threshold_anomaly = new_threshold - new_climatology\n",
    "    \n",
    "    # Ignore divide by zero errors\n",
    "    nperr = np.seterr(divide='ignore')\n",
    "\n",
    "    def calc_severity_helper(da, *args, **kwargs):\n",
    "        if da.size == 0:\n",
    "            return da\n",
    "    \n",
    "        coords = {}\n",
    "        for k,v in obs_aus_tmax.coords.items():\n",
    "            if k == 'time':\n",
    "                continue\n",
    "            coords[k] = slice(v[0], v[-1])\n",
    "    \n",
    "        anomaly = da - new_climatology.sel(coords)\n",
    "        severity = anomaly / threshold_anomaly.sel(coords)\n",
    "        return severity\n",
    "\n",
    "    data = data.chunk({'time': None})\n",
    "    r = data.map_blocks(calc_severity_helper)\n",
    "    \n",
    "    np.seterr(**nperr)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns values with at least n contiguous points around them. I am using n=3, to define a terrestrial heatwave as an event where the daily tmax exceeds the 90th percentile for at least 3 consecutive days (Perkins and Alexander, 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atleastn(da, n, dim='time'):\n",
    "\n",
    "    def atleastn_helper(array, n, axis):\n",
    "        count = np.zeros_like(np.take(array, 0,axis=axis), dtype='i4')\n",
    "        mask = np.empty_like(np.take(array, 0,axis=axis), dtype='bool')\n",
    "        mask = True\n",
    "    \n",
    "        for i in range(array.shape[axis]):\n",
    "            array_slice = np.take(array, i, axis=axis)\n",
    "        \n",
    "            # Increase the count when there is a valid value, reset when there is not\n",
    "            # This was initially set to 0, now I have changed it to 1 to detect only valid heatwave days \n",
    "            # The previous way was fine as long as I masked values less than or equal to 1, and they were white on the colour bar\n",
    "            count = np.where(array_slice > 1, count + 1, 0)\n",
    "        \n",
    "            # Add new points when the contiguous count exceeds the threshold\n",
    "            mask = np.where(count >= n, False, mask)\n",
    "            \n",
    "        out_slice = np.take(array, array.shape[axis]//2, axis=axis)\n",
    "        return np.where(mask, np.nan, out_slice)\n",
    "    \n",
    "    def atleastn_dask_helper(array, axis, **kwargs):\n",
    "        r = dask.array.map_blocks(atleastn_helper, array, drop_axis=axis, axis=axis, n=n, dtype=array.dtype)\n",
    "        return r\n",
    "    \n",
    "    if isinstance(da.data, dask.array.Array):\n",
    "        reducer = atleastn_dask_helper\n",
    "    else:\n",
    "        reducer = atleastn_helper\n",
    "        \n",
    "    return da.rolling({dim: n*2-1}, center=True, min_periods=n).reduce(reducer, n=n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening files and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_climatology = xr.open_dataarray('/g/data/e14/cp3790/Charuni/NCI/ERA5-T2M/climatology-australia.nc')\n",
    "threshold = xr.open_dataarray('/g/data/e14/cp3790/Charuni/NCI/ERA5-T2M/threshold-australia.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('/g/data/e14/cp3790/Charuni/NCI/ERA5-T2M/era5_dailytmax_*.nc'))\n",
    "\n",
    "obs_aus = (xr.open_mfdataset(files, combine='nested', concat_dim='time', chunks={'latitude': 10})\n",
    "           .sel(time=slice('1982', '2018'), longitude=slice(113, 154), latitude=slice(-10, -44)))\n",
    "obs_aus_tmax = obs_aus[\"dailytmax\"] - 273.15\n",
    "obs_aus_tmax.attrs['units'] = 'deg C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the mean climatology and 90th percentile climatology (threshold) repeatable so that their sizes are compatible with the size of the obs_aus_tmax data using the 'copy_clim' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_climatology = xr.DataArray(np.empty(obs_aus_tmax.shape),\n",
    "                               coords=obs_aus_tmax.coords,\n",
    "                               dims=obs_aus_tmax.dims,\n",
    "                               name=\"climatology\")\n",
    "new_climatology = new_climatology.groupby(new_climatology.time.dt.dayofyear).apply(copy_clim,input_da=mean_climatology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_threshold= xr.DataArray(np.empty(obs_aus_tmax.shape),\n",
    "                               coords=obs_aus_tmax.coords,\n",
    "                               dims=obs_aus_tmax.dims,\n",
    "                               name=\"threshold\")\n",
    "new_threshold=new_threshold.groupby(new_threshold.time.dt.dayofyear).apply(copy_clim,input_da=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating severity using 'map_blocks()', which enables the severity calculation to run on each timeseries chunk, facilitating parallel computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thw_severity = calc_severity(obs_aus_tmax, new_climatology, new_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in the days where the daily tmax has exceeded the threshold. If severity > 1, this means that daily tmax > threshold (from the definition of severity). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 74 ms, total: 374 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "candidates = thw_severity.where(thw_severity > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to netCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the terrestrial heatwave days across Australia from 1982-2018 will be stored in filtered_severity_final_new_mask.nc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 ms, sys: 1.62 ms, total: 43.1 ms\n",
      "Wall time: 42.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Next, we mask out points where there are less than 3 contiguous points in the time dimension\n",
    "oscar = atleastn(candidates, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset({'severity': oscar}).to_netcdf('/g/data/e14/cp3790/Charuni/filtered_severity_final_new_mask_CP.nc',\n",
    "                                              encoding={'severity': \n",
    "                                                        {'chunksizes': (100, oscar.shape[1], oscar.shape[2]),\n",
    "                                                         'zlib': True,\n",
    "                                                         'shuffle': True, \n",
    "                                                         'complevel': 2}})   \n",
    "\n",
    "# compression level (complevel) up to 6 is fine, >6 and it starts giving trouble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "305.85px",
    "left": "1531px",
    "right": "20px",
    "top": "120px",
    "width": "349px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
